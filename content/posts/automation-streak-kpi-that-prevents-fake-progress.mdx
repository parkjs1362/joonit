---
title: '자동화 스트릭 KPI 설계: 가짜 진척을 막는 기준'
description: 자동화는 만든 개수보다 실사용 연속성이 중요합니다. streak KPI를 설계할 때 꼭 넣어야 할 조건을 정리합니다.
date: '2026-02-18'
category: 개발
tags:
  - KPI
  - 자동화
  - 회고
  - 운영
---
자동화 프로젝트는 착시가 쉽게 생깁니다.  
워크플로우 수는 늘어나는데 실제로는 잘 안 쓰는 경우가 많습니다.

노트 시스템 회고에서 유효했던 지표는 단순 실행 횟수가 아니라 **실사용 스트릭(streak)**이었습니다.

## 1) 스트릭의 통과 조건을 명확히 만든다

스트릭은 “실행됨”이 아니라 “의미 있게 사용됨”을 기준으로 설계해야 합니다.

- prompt 자동화: real run 1회 이상
- screenshot 카드: real write 1회 이상
- 두 조건 모두 충족한 날만 성공

한 축만 성공한 날을 실패로 처리해야 루프가 균형을 유지합니다.

## 2) dry-run은 분리 지표로 본다

dry-run은 유용하지만 실사용을 대체하지 않습니다.

- 운영 지표: real run
- 품질 지표: dry-run 대비 실패율
- 학습 지표: 평균 텍스트 길이, 평균 요약 라인

이렇게 분리하면 “테스트만 많이 한 주”를 성과로 착각하지 않게 됩니다.

## 3) 실패 원인을 로그 스키마에 포함한다

스트릭이 깨진 날은 보통 원인이 반복됩니다.

- clipboard fail
- open fail
- input missing

원인 코드를 로그에 고정 필드로 넣어야, 개선 우선순위를 데이터로 정할 수 있습니다.

## 4) KPI는 주간 의사결정과 연결해야 한다

스트릭 자체보다 중요한 건 다음 결정입니다.

- Keep: 유지할 루프 1개
- Drop: 중단할 루프 1개
- Next: 다음 주 실험 1개

KPI가 결정으로 이어지지 않으면 숫자 수집만 남습니다.

## 근거: 자동화 피로는 기능 부족이 아니라 운영 착시에서 온다

운영 로그를 보면 “실행된 것처럼 보이는 자동화”가 피로를 만듭니다.

- dry-run 비중이 높을수록 체감 효과는 낮아집니다.
- 실패 원인 분류가 없으면 같은 장애를 반복합니다.
- 스트릭 조건이 느슨하면 개선 우선순위가 흐려집니다.

## 실행 방법: 7일 스트릭 운영 템플릿

1. 실사용 조건을 2개 이상으로 정의한다.
2. 로그에서 real/dry-run을 분리 저장한다.
3. 하루 종료 시 성공/실패를 자동 집계한다.
4. 주말에 실패 원인 Top 3만 리뷰한다.
5. Keep/Drop/Next를 확정하고 다음 주 조건을 고정한다.

## 오늘의 메모

자동화 성과는 “만든 개수”가 아니라  
“끊기지 않는 사용일수”로 보는 게 정확합니다.

## 보강: 근거와 실행 설계

### 근거
이 주제는 실무 적용에서 반복적으로 발생하는 패턴을 기반으로 정리했습니다. 단순 팁이 아니라 실제 운영 기록에서 재현된 문제와 해결 순서를 중심으로 작성했습니다. 특히 `실행 빈도`, `실패 유형`, `복구 리드타임` 세 지표를 함께 보면서 “지속 가능한 방식”인지 먼저 확인했습니다.

### 방법
실행 순서는 항상 **기준선 측정 → 작은 변경 → 로그 비교**로 고정했습니다. 첫 3일은 아무것도 바꾸지 않고 현재 상태를 수치화하고, 다음 7일은 변경을 1~2개만 적용한 뒤 영향 범위를 확인합니다. 마지막 4일은 남은 노이즈를 줄이고 문서화해 팀/미래의 나에게 전달 가능한 운영 기준으로 확정합니다.

### 체크포인트
- 시작 전 성공 조건을 숫자로 정의했는가
- 변경은 한 번에 1~2개만 적용했는가
- 실패 상황에서 되돌리는 경로가 준비되어 있는가
- 주간 리뷰에서 Keep/Drop/Next를 실제로 결정했는가

### 측정 지표
이 글의 실행 품질은 체감이 아니라 로그로 판단합니다. 예를 들어 실행 성공률은 7일 이동평균으로 보고, 경고 노이즈는 “동일 원인 경고의 중복 발생 횟수”로 계산합니다. 또한 문제를 발견한 시점부터 정상 상태로 되돌리기까지 걸린 시간(복구 리드타임)을 같이 기록하면, 화려한 자동화보다 운영성이 높은 방식을 분명히 구분할 수 있습니다.

### 실패 복구
가장 흔한 실패는 “도구 추가 속도가 운영 속도보다 빠른 상태”입니다. 이때는 신규 기능을 잠시 멈추고, 자주 쓰는 흐름 3개만 남겨 안정화합니다. 이후 실패 로그를 원인 단위로 묶어 재발 방지 규칙을 추가하면, 다음 주부터는 같은 문제를 훨씬 짧은 시간 안에 처리할 수 있습니다.

### 14일 적용 프로토콜
1일차는 현재 프로세스를 있는 그대로 캡처해 기준선을 만든다. 2~3일차는 실패 패턴을 원인별로 분류한다. 4~10일차는 가장 영향이 큰 병목 하나만 개선한다. 11~14일차는 개선 전/후 수치를 비교해 문서로 확정한다. 이 루프를 두 번만 반복해도 글의 방법론이 추상적 조언에서 운영 지침으로 바뀝니다.

## 보강: 실행 디테일과 검증 기준

### 운영 절차를 문서가 아니라 런북으로 고정하기
실무에서 가장 빨리 무너지는 지점은 "좋은 원칙" 자체가 아니라, 원칙을 실행으로 옮기는 마지막 2~3단계입니다. 그래서 운영 글은 반드시 **누가, 언제, 어떤 로그를 남기며, 실패하면 어디로 되돌아가는지**를 명확히 적어야 합니다. 예를 들어 자동화/배포/라우팅 주제라면 시작 전 기준선 수집 항목(실행 횟수, 실패 코드, 평균 처리 시간), 적용 중 확인 항목(경고 증가 여부, 누락 작업 발생 여부), 적용 후 검증 항목(복구 시간, 재발률)을 구분해 두는 편이 좋습니다. 이 구분이 없으면 개선 활동이 "바뀐 것 같다" 수준에서 끝나고, 2주 후에는 다시 감으로 돌아가기 쉽습니다.

### 2주 적용 루프(측정-적용-회고)
1주차는 기준선 확보에 집중합니다. 기능을 더하지 말고 현재 프로세스를 그대로 돌려서 병목을 찾습니다. 2주차는 병목 1개만 골라 개선합니다. 개선 수단은 간단해야 하며(스크립트 옵션 추가, 체크리스트 분리, 경고 임계값 조정), 결과는 반드시 이전 주와 같은 단위로 비교합니다. 이 과정을 반복하면 “복잡한 시스템”보다 “관리 가능한 시스템”이 남습니다. 특히 블로그 운영처럼 도구가 계속 늘어나는 환경에서는 **추가 속도보다 정착 속도**를 지표로 삼아야 실사용성이 올라갑니다.

### 실패 패턴과 복구 시나리오
가장 흔한 실패 패턴은 세 가지입니다. 첫째, 도구 수는 늘었지만 핵심 흐름이 분산되어 호출 지점이 많아지는 문제. 둘째, 로그는 쌓이는데 기준값이 없어 해석이 불가능한 문제. 셋째, 실패했을 때 복구 순서가 문서에만 있고 실제 명령으로 자동화되지 않은 문제입니다. 복구는 "원인 분석"보다 먼저 "서비스 안정화"부터 처리해야 합니다. 즉시 중단 가능한 스위치(report-only), 되돌리기 가능한 안전 지점(이전 설정/백업), 재실행 가능한 진단 명령(health-check)을 먼저 실행한 뒤 원인을 좁혀야 장애 시간이 짧아집니다.

### 실행 체크리스트(실전)
- 변경 전에 7일 기준선(실행 성공률/평균 처리시간/경고 수)을 저장한다
- 변경은 한 번에 1개만 배포하고, 배포 후 24시간 관찰한다
- 경고가 기준 대비 20% 이상 증가하면 즉시 report-only 모드로 전환한다
- 주간 리뷰에서 Keep/Drop/Next를 각각 1개 이상 결정한다
- 다음 주 문서를 "배운 점"이 아니라 "다음 실행 규칙" 문장으로 끝낸다
